{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.01625\n",
      "Test accuracy: 0.02\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ================================= #\n",
    "#\n",
    "# Logistic regression\n",
    "#\n",
    "# ================================= #\n",
    "\n",
    "\n",
    "def sigmoid(matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    :param matrix: Matrix on which sigmoid must be applied\n",
    "    :return sigmoid_mat: Sigmoid applied on matrix entry-wise\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-matrix))\n",
    "\n",
    "\n",
    "def normalize_data(data: np.ndarray,\n",
    "                   mean: np.ndarray = None,\n",
    "                   std: np.ndarray = None) -> (np.ndarray, np.ndarray, np.ndarray):\n",
    "    \"\"\"\n",
    "    :param data: (num_examples, num_features) Data matrix\n",
    "    :param mean: (num_features, 1)  Data mean\n",
    "    :param std: (num_features, 1) Data standard deviation\n",
    "    :return normalized_data: (num_examples, num_features) Normalized data matrix\n",
    "    :return mean: (num_features, 1) Mean used for normalizing\n",
    "    :return std: (num_features, 1) Standard deviation used for normalizing\n",
    "    \"\"\"\n",
    "\n",
    "    if mean is None:\n",
    "        mean = data.mean(axis=0).reshape((-1, 1))\n",
    "\n",
    "    if std is None:\n",
    "        std = data.std(axis=0).reshape((-1, 1))\n",
    "\n",
    "    normalized_data = data - np.repeat(mean.T, repeats=data.shape[0], axis=0)\n",
    "    normalized_data = normalized_data / np.repeat(std.T, repeats=data.shape[0], axis=0)\n",
    "    return normalized_data, mean, std\n",
    "\n",
    "\n",
    "def predict(data: np.ndarray,\n",
    "            weights: np.ndarray,\n",
    "            bias: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    :param data: (num_examples, num_features) Data matrix\n",
    "    :param weights: (num_features, 1) Weight vector\n",
    "    :param bias: Scalar bias\n",
    "    :return predictions: (num_examples, 1) Predicted target values\n",
    "    \"\"\"\n",
    "    return sigmoid(np.matmul(data, weights) + bias)\n",
    "\n",
    "\n",
    "def accuracy(targets: np.ndarray,\n",
    "             predictions: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    :param targets: (num_examples, 1) Target labels\n",
    "    :param predictions: (num_examples, 1) Predicted labels\n",
    "    :return accuracy: Computed accuracy\n",
    "    \"\"\"\n",
    "    return (targets == predictions).mean()\n",
    "\n",
    "\n",
    "def train(data: np.ndarray,\n",
    "          targets: np.ndarray,\n",
    "          reg_param: float = 0.1,\n",
    "          max_iters: int = 1000,\n",
    "          lr: float = 0.1) -> (np.ndarray, float):\n",
    "    \"\"\"\n",
    "    :param data: (num_examples, num_features) Data matrix\n",
    "    :param targets: (num_examples, 1) Target values\n",
    "    :param reg_param: Regularization parameter\n",
    "    :param max_iters: Maximum number of iterations for gradient descent\n",
    "    :param lr: Learning rate for gradient descent\n",
    "    :return weights: (num_features, 1) Weight vector\n",
    "    :return bias: Scalar bias\n",
    "    \"\"\"\n",
    "    # Initialize the weights and bias\n",
    "    w = np.random.normal(size=(data.shape[1], 1))\n",
    "    b = 0\n",
    "\n",
    "    # Learn the parameters using gradient descent\n",
    "    for iter_idx in range(max_iters):\n",
    "        predictions = predict(data, w, b)\n",
    "        grad_w = (np.matmul(data.T, (predictions - targets)) + reg_param * w) / data.shape[0]\n",
    "        grad_b = np.mean(predictions - targets)\n",
    "        w = w - lr * grad_w\n",
    "        b = b - lr * grad_b\n",
    "\n",
    "        if np.linalg.norm(grad_w) + np.linalg.norm(grad_b) <= 0.001:\n",
    "            break\n",
    "\n",
    "    return w, b\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Control variables\n",
    "    num_examples = 1000\n",
    "    num_features = 2\n",
    "\n",
    "    # Initialize optimal w and b\n",
    "    w_star = np.random.normal(size=(num_features, 1))\n",
    "    b_star = np.random.normal()\n",
    "\n",
    "    # Generate random data\n",
    "    all_data = np.random.normal(size=(num_examples, num_features))\n",
    "    all_targets = sigmoid(np.matmul(all_data, w_star) + b_star) >= 0.5\n",
    "\n",
    "    # Split into train and test set\n",
    "    all_indices = list(range(num_examples))\n",
    "    np.random.shuffle(all_indices)\n",
    "    train_indices = all_indices[:int(0.8 * num_examples)]\n",
    "    test_indices = all_indices[int(0.8 * num_examples):]\n",
    "    train_data = all_data[train_indices, :]\n",
    "    train_targets = all_targets[train_indices, :]\n",
    "    test_data = all_data[test_indices, :]\n",
    "    test_targets = all_targets[test_indices, :]\n",
    "\n",
    "    # Normalize the data\n",
    "    normalized_train, data_mean, data_std = normalize_data(train_data)\n",
    "    normalized_test, _, _ = normalize_data(test_data, data_mean, data_std)\n",
    "\n",
    "    # Train the model\n",
    "    w_hat, b_hat = train(normalized_train, train_targets)\n",
    "\n",
    "    # Get predictions on train and test set\n",
    "    train_preds = predict(normalized_train, w_hat, b_hat) >= 0.5\n",
    "    #print(\"train preds\", train_preds , \"predicted \" ,predict(normalized_train, w_hat, b_hat) )\n",
    "    test_preds = predict(normalized_test, w_hat, b_hat) >= 0.5\n",
    "\n",
    "    # Compute training and test accuracy\n",
    "    train_accuracy = accuracy(train_targets, train_preds)\n",
    "    test_accuracy = accuracy(test_targets, test_preds)\n",
    "    print('Train accuracy:', train_accuracy)\n",
    "    print('Test accuracy:', test_accuracy)\n",
    "\n",
    "    plt.plot(normalized_train[:, 0], train_targets[:], 'r.')\n",
    "    #plt.plot(train_data[:, 0], train_preds[:, 0], 'b.')\n",
    "    plt.plot(normalized_test[:, 0], test_preds[:, 0], 'b.')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sampleenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

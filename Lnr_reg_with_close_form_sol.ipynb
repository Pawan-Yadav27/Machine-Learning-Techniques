{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape  1795 99\n",
      "target data shape  1795\n",
      "train data shape  1795 99\n",
      "target data shape  1795\n",
      "train data shape  1795 99\n",
      "target data shape  1795\n",
      "train data shape  1795 99\n",
      "target data shape  1795\n",
      "train data shape  1796 99\n",
      "target data shape  1796\n",
      "train data shape  1796 99\n",
      "target data shape  1796\n",
      "train data shape  1796 99\n",
      "target data shape  1796\n",
      "train data shape  1796 99\n",
      "target data shape  1796\n",
      "train data shape  1796 99\n",
      "target data shape  1796\n",
      "train data shape  1796 99\n",
      "target data shape  1796\n",
      "0.1269744022433448\n",
      "0.29890191228509017\n",
      "0.009335784264072437\n",
      "0.024160145461283825\n",
      "0.03571558776708461\n",
      "0.038161850820479806\n",
      "0.04901322870148985\n",
      "0.06150893777464165\n",
      "0.16062853992839057\n",
      "0.28442249481163195\n",
      "optimal mean error  0.009335784264072437 optimal lembda  0.0005\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ================================= #\n",
    "#\n",
    "# Linear regression\n",
    "#\n",
    "# ================================= #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict(data: np.ndarray,\n",
    "            weights: np.ndarray,\n",
    "            b : float\n",
    "            ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    :param data: (num_examples, num_features) Data matrix\n",
    "    :param weights: (num_features, 1) Weight vector\n",
    "    :param bias: Scalar bias\n",
    "    :return predictions: (num_examples, 1) Predicted target values\n",
    "    \"\"\"\n",
    "    bias = [b]*data.shape[0]\n",
    "    return np.matmul(data, weights) + bias\n",
    "\n",
    "\n",
    "def cost(targets: np.ndarray,\n",
    "         predictions: np.ndarray,\n",
    "         weights : np.ndarray,\n",
    "         reg_param: float) -> float:\n",
    "    \"\"\"\n",
    "    :param targets: (num_examples, 1) Target values\n",
    "    :param predictions: (num_examples, 1) Predicted values\n",
    "    :return error: Computed mean-squared error\n",
    "    \"\"\"\n",
    "    #print(\"shape of prediction\" , predictions.shape[0] , predictions.shape[1])\n",
    "    #print(\"shape of target\" , weights.shape[0] , weights.shape[1])\n",
    "    #print(\"lembda \", reg_param)\n",
    "    w = np.squeeze(np.asarray(weights))\n",
    "    return 0.5 * np.mean(np.square(targets - predictions)) + (reg_param * np.dot(w , w))/2\n",
    "\n",
    "\n",
    "def train(data: np.ndarray,\n",
    "          targets: np.ndarray,\n",
    "          reg_param: float\n",
    "          ) -> (np.ndarray, float):\n",
    "    \"\"\"\n",
    "    :param data: (num_examples, num_features) Data matrix\n",
    "    :param targets: (num_examples, 1) Target values\n",
    "    :param reg_param: Regularization parameter\n",
    "    :param max_iters: Maximum number of iterations for gradient descent\n",
    "    :param lr: Learning rate for gradient descent\n",
    "    :return weights: (num_features, 1) Weight vector\n",
    "    :return bias: Scalar bias\n",
    "    \"\"\"\n",
    "    # Close form Solution\n",
    "#     I = np.identity(100)\n",
    "#     w = np.linalg.inv(np.dot(np.transpose(data) , data) + reg_param* I)\n",
    "#     w = np.dot(w , np.transpose(data))\n",
    "#     w = np.dot(w , targets.reshape(-1,1))\n",
    "    num_sentences = data.shape[0]\n",
    "    dim = data.shape[1]\n",
    "    xixit = np.zeros((dim, dim)) #[[0]*dim]*dim \n",
    "    sum_xixit = np.zeros((dim, dim))\n",
    "    oneDD = np.ones((dim, dim)) \n",
    "    for i in range(num_sentences):\n",
    "        for j in range(dim):\n",
    "            value = data[i][j]\n",
    "            xixit[j , :]  = value * data[i , : ] \n",
    "        sum_xixit += xixit \n",
    "        \n",
    "    #print(\"shape of sum_xixit\" , sum_xixit.shape[0] , sum_xixit.shape[1])\n",
    "    sum_xi = np.zeros((1, dim))\n",
    "    for i in range(num_sentences):\n",
    "        sum_xi += data[i , :]\n",
    "    #print(\"shape of sum_xi\" , sum_xi.shape[0] , sum_xi.shape[1])\n",
    "    \n",
    "    mul_sum_xi_sum_xit = np.zeros((dim, dim))\n",
    "    for j in range(dim):\n",
    "            value = sum_xi[0][j]\n",
    "            mul_sum_xi_sum_xit[j , :]  = value * sum_xi\n",
    "    #print(\"shape of mul_sum_xi_sum_xit\" , mul_sum_xi_sum_xit.shape[0] , mul_sum_xi_sum_xit.shape[1])\n",
    "    \n",
    "    sum_xiyi = np.zeros((1,dim))\n",
    "    for j in range(num_sentences):\n",
    "        sum_xiyi += targets[j]*data[j , :]\n",
    "    #print(\"shape of sum_xiyi\" , sum_xiyi.reshape(-1,1).shape[0] , sum_xiyi.reshape(-1,1).shape[1])\n",
    "    #sum_xiyi.reshape(-1,1)\n",
    "    \n",
    "    sum_yi = 0\n",
    "    for j in range(num_sentences):\n",
    "        sum_yi += targets[j]\n",
    "    mul_sum_yi_sum_xi = sum_yi * sum_xi\n",
    "    #print(\"shape of mul_sum_yi_sum_xi\" , mul_sum_yi_sum_xi.shape[0] , mul_sum_yi_sum_xi.shape[1])\n",
    "    \n",
    "    w = np.dot(np.linalg.inv((1/num_sentences)*sum_xixit - (1/np.square(num_sentences) * mul_sum_xi_sum_xit)\n",
    "                     - reg_param * oneDD) ,\n",
    "               ((1/num_sentences) * sum_xiyi.reshape(-1,1)- (1/np.square(num_sentences))*mul_sum_yi_sum_xi.reshape(-1,1)))\n",
    "    \n",
    "    #print(\"shape of w\" , w.shape[0] , w.shape[1])\n",
    "    b = 0 \n",
    "    for j in range(num_sentences):\n",
    "        b += targets[j] - np.dot(data[j , :] , w)\n",
    "    b = (-1/num_sentences) * b\n",
    "    return w, b\n",
    "    \n",
    "    \n",
    "\n",
    "lembda = [0.0, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]         \n",
    "optimal_error = 1000\n",
    "optimal_lembda =0\n",
    "if __name__ == '__main__':\n",
    "  \n",
    "       \n",
    "    #print(\"train data shape \", train_data.shape[0] , train_data.shape[1])\n",
    "    #print(\"target data shape \", train_targets.shape[0])\n",
    "    for id in range(10):\n",
    "        train_data = [[1]*99]*1\n",
    "        train_targets = np.zeros(1)\n",
    "        if (not(id == 0) ):\n",
    "            train_data0= np.load('D:/.ipynb_checkpoints/lr_data/Fold1/features.npy')\n",
    "            #print(\"train data shape \", train_data.shape[0] , train_data.shape[1])\n",
    "            train_targets0 = np.load('D:/.ipynb_checkpoints/lr_data/Fold1/target.npy')\n",
    "            #print(\"target data shape \", train_targets.shape[0])\n",
    "            train_data = np.concatenate((train_data,train_data0 ))\n",
    "            train_targets = np.concatenate((train_targets , train_targets0))\n",
    "        if (not(id == 1)):\n",
    "            train_data1 = np.load('D:/.ipynb_checkpoints/lr_data/Fold2/features.npy')\n",
    "            train_targets1 = np.load('D:/.ipynb_checkpoints/lr_data/Fold2/target.npy')\n",
    "            train_data = np.concatenate((train_data,train_data1 ))\n",
    "            train_targets = np.concatenate((train_targets , train_targets1))\n",
    "        if (not(id == 2)):\n",
    "            train_data2 = np.load('D:/.ipynb_checkpoints/lr_data/Fold3/features.npy')\n",
    "            train_targets2 = np.load('D:/.ipynb_checkpoints/lr_data/Fold3/target.npy')\n",
    "            train_data = np.concatenate((train_data,train_data2 ))\n",
    "            train_targets = np.concatenate((train_targets , train_targets2))\n",
    "        if (not(id == 3)):\n",
    "            train_data3 = np.load('D:/.ipynb_checkpoints/lr_data/Fold4/features.npy')\n",
    "            train_targets3 = np.load('D:/.ipynb_checkpoints/lr_data/Fold4/target.npy')\n",
    "            train_data = np.concatenate((train_data,train_data3 ))\n",
    "            train_targets = np.concatenate((train_targets , train_targets3))\n",
    "        if (not(id == 4)):\n",
    "            train_data4 = np.load('D:/.ipynb_checkpoints/lr_data/Fold5/features.npy')\n",
    "            train_targets4 = np.load('D:/.ipynb_checkpoints/lr_data/Fold5/target.npy')\n",
    "            train_data = np.concatenate((train_data,train_data4 ))\n",
    "            train_targets = np.concatenate((train_targets , train_targets4))\n",
    "        if (not(id == 5)):\n",
    "            train_data5 = np.load('D:/.ipynb_checkpoints/lr_data/Fold6/features.npy')\n",
    "            train_targets5 = np.load('D:/.ipynb_checkpoints/lr_data/Fold6/target.npy')\n",
    "            train_data = np.concatenate((train_data,train_data5 ))\n",
    "            train_targets = np.concatenate((train_targets , train_targets5))\n",
    "        if (not(id == 6)):\n",
    "            train_data6 = np.load('D:/.ipynb_checkpoints/lr_data/Fold7/features.npy')\n",
    "            train_targets6 = np.load('D:/.ipynb_checkpoints/lr_data/Fold7/target.npy')\n",
    "            train_data = np.concatenate((train_data,train_data6 ))\n",
    "            train_targets = np.concatenate((train_targets , train_targets6))\n",
    "        if (not(id == 7)):\n",
    "            train_data7 = np.load('D:/.ipynb_checkpoints/lr_data/Fold8/features.npy')\n",
    "            train_targets7 = np.load('D:/.ipynb_checkpoints/lr_data/Fold8/target.npy')\n",
    "            train_data = np.concatenate((train_data,train_data7 ))\n",
    "            train_targets = np.concatenate((train_targets , train_targets7))\n",
    "        if (not(id == 8)):\n",
    "            train_data8 = np.load('D:/.ipynb_checkpoints/lr_data/Fold9/features.npy')\n",
    "            train_targets8 = np.load('D:/.ipynb_checkpoints/lr_data/Fold9/target.npy')\n",
    "            train_data = np.concatenate((train_data,train_data8 ))\n",
    "            train_targets = np.concatenate((train_targets , train_targets8))\n",
    "        if (not(id == 9)):\n",
    "            train_data9 = np.load('D:/.ipynb_checkpoints/lr_data/Fold10/features.npy')\n",
    "            train_targets9 = np.load('D:/.ipynb_checkpoints/lr_data/Fold10/target.npy')\n",
    "            train_data = np.concatenate((train_data,train_data9 ))\n",
    "            train_targets = np.concatenate((train_targets , train_targets9))\n",
    "\n",
    "        if (id == 0 ):\n",
    "            test_data = np.load('D:/.ipynb_checkpoints/lr_data/Fold1/features.npy')\n",
    "            #print(\"train data shape \", test_data.shape[0] , train_data.shape[1])\n",
    "            test_targets = np.load('D:/.ipynb_checkpoints/lr_data/Fold1/target.npy')\n",
    "            #print(\"target data shape \", test_targets.shape[0])\n",
    "        elif (id == 1):\n",
    "            test_data = np.load('D:/.ipynb_checkpoints/lr_data/Fold2/features.npy')\n",
    "            test_targets = np.load('D:/.ipynb_checkpoints/lr_data/Fold2/target.npy')\n",
    "        elif (id == 2):\n",
    "            test_data = np.load('D:/.ipynb_checkpoints/lr_data/Fold3/features.npy')\n",
    "            test_targets = np.load('D:/.ipynb_checkpoints/lr_data/Fold3/target.npy')\n",
    "        elif (id == 3):\n",
    "            test_data = np.load('D:/.ipynb_checkpoints/lr_data/Fold4/features.npy')\n",
    "            test_targets = np.load('D:/.ipynb_checkpoints/lr_data/Fold4/target.npy')\n",
    "        elif (id == 4):\n",
    "            test_data = np.load('D:/.ipynb_checkpoints/lr_data/Fold5/features.npy')\n",
    "            test_targets = np.load('D:/.ipynb_checkpoints/lr_data/Fold5/target.npy')\n",
    "        elif (id == 5):\n",
    "            test_data = np.load('D:/.ipynb_checkpoints/lr_data/Fold6/features.npy')\n",
    "            test_targets = np.load('D:/.ipynb_checkpoints/lr_data/Fold6/target.npy')\n",
    "        elif (id == 6):\n",
    "            test_data = np.load('D:/.ipynb_checkpoints/lr_data/Fold7/features.npy')\n",
    "            test_targets = np.load('D:/.ipynb_checkpoints/lr_data/Fold7/target.npy')\n",
    "        elif (id == 7):\n",
    "            test_data = np.load('D:/.ipynb_checkpoints/lr_data/Fold8/features.npy')\n",
    "            test_targets = np.load('D:/.ipynb_checkpoints/lr_data/Fold8/target.npy')\n",
    "        elif (id == 8):\n",
    "            test_data = np.load('D:/.ipynb_checkpoints/lr_data/Fold9/features.npy')\n",
    "            test_targets = np.load('D:/.ipynb_checkpoints/lr_data/Fold9/target.npy')\n",
    "        elif (id == 9):\n",
    "            test_data = np.load('D:/.ipynb_checkpoints/lr_data/Fold10/features.npy')\n",
    "            test_targets = np.load('D:/.ipynb_checkpoints/lr_data/Fold10/target.npy')\n",
    "            \n",
    "   \n",
    "        print(\"train data shape \", train_data.shape[0] , train_data.shape[1])\n",
    "        print(\"target data shape \", train_targets.shape[0])\n",
    "        #append_one = np.ones(train_data.shape[0])\n",
    "        #train_data = np.concatenate((append_one.reshape(-1,1),train_data ), axis = 1)\n",
    "            \n",
    "        Error_array = np.zeros((10 , len(lembda)))\n",
    "\n",
    "        for idx in range(len(lembda)):\n",
    "            # Train the model\n",
    "            w , b = train(train_data, train_targets.reshape(-1,1),lembda[idx])\n",
    "            #print(\"shape of w\" , w.shape[0] , w.shape[1])\n",
    "            #print(\"lembda\", lembda[idx])\n",
    "            train_preds = predict(train_data, w , b)\n",
    "            train_error = cost(train_targets.reshape(-1,1), train_preds, w , lembda[idx] )\n",
    "            \n",
    "            test_preds = predict(test_data, w ,b )\n",
    "            test_error = cost(test_targets.reshape(-1,1), test_preds,w, lembda[idx] )\n",
    "            Error_array[id][idx] = test_error\n",
    "#             if(test_error <= optimal_error):\n",
    "#                 optimal_error = train_error\n",
    "#                 optimal_lembda = lembda[idx]\n",
    "#                 w_star = w\n",
    "#                 b_star = b\n",
    "            \n",
    "        #print(\"optimal error \" , optimal_error , \"optimal lembda \", optimal_lembda)\n",
    "        \n",
    "        #append_one = np.ones(test_data.shape[0])\n",
    "        #test_data = np.concatenate((append_one.reshape(-1,1),test_data), axis = 1)\n",
    "        #test_preds = predict(test_data, w_star ,b_star )\n",
    "        #test_error = cost(test_targets.reshape(-1,1), test_preds,w_star, optimal_lembda )\n",
    "        #print(\"test data shape \", test_data.shape[0] , test_data.shape[1])\n",
    "        #print(\"test target data shape \", test_targets.shape[0])\n",
    "        #print(\"test error\", test_error)\n",
    "        \n",
    "        #plot the function - \n",
    "        \n",
    "        #plt.plot(train_data[:, 3], train_targets[:], 'r.')\n",
    "        #plt.plot(train_data[:, 0], train_preds[:, 0], 'b.')\n",
    "        #plt.plot(test_data[:, 3], test_preds[:, 0], 'b.')\n",
    "        #plt.show()\n",
    "\n",
    "for idx in range(len(lembda)):\n",
    "    print(np.mean(Error_array[: , idx]))\n",
    "    if(np.mean(Error_array[: , idx]) <= optimal_error):\n",
    "        optimal_error = np.mean(Error_array[: , idx])\n",
    "        optimal_lembda = lembda[idx]\n",
    "print(\"optimal mean error \" , optimal_error , \"optimal lembda \", optimal_lembda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-51c25c7a7b15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mappend_one\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mappend_one\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mappend_one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mappend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mappend_one\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mappend_one\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmat1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#,[3 ,4, 8],[2, 12, 3])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "append_one = np.ones(10)\n",
    "append_one = 1+append_one\n",
    "append = [[2]*10]*10\n",
    "append_one = np.concatenate((append_one.reshape(-1,1) , append), axis=1)\n",
    "mat1 = ([1, 6, 5]) #,[3 ,4, 8],[2, 12, 3])\n",
    "mat2 = ([3, 4, 6]) #,[5, 6, 7],[6,56, 7])\n",
    "  \n",
    "# This will return dot product\n",
    "res = np.dot(np.transpose(mat1) , mat1)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sampleenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
